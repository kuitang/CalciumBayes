%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Kui Tang at 2012-01-26 02:46:28 -0500 


%% Saved with string encoding Unicode (UTF-8) 



@article{perin2011,
	Abstract = {Neuronal circuitry is often considered a clean slate that can be dynamically and arbitrarily molded by experience. However, when we investigated synaptic connectivity in groups of pyramidal neurons in the neocortex, we found that both connectivity and synaptic weights were surprisingly predictable. Synaptic weights follow very closely the number of connections in a group of neurons, saturating after only 20% of possible connections are formed between neurons in a group. When we examined the network topology of connectivity between neurons, we found that the neurons cluster into small world networks that are not scale-free, with less than 2 degrees of separation. We found a simple clustering rule where connectivity is directly proportional to the number of common neighbors, which accounts for these small world networks and accurately predicts the connection probability between any two neurons. This pyramidal neuron network clusters into multiple groups of a few dozen neurons each. The neurons composing each group are surprisingly distributed, typically more than 100 Î¼m apart, allowing for multiple groups to be interlaced in the same space. In summary, we discovered a synaptic organizing principle that groups neurons in a manner that is common across animals and hence, independent of individual experiences. We speculate that these elementary neuronal groups are prescribed Lego-like building blocks of perception and that acquired memory relies more on combining these elementary assemblies into higher-order constructs.},
	Author = {Perin, Rodrigo and Berger, Thomas K. and Markram, Henry},
	Date-Added = {2012-01-26 07:39:24 +0000},
	Date-Modified = {2012-01-26 07:39:30 +0000},
	Doi = {10.1073/pnas.1016051108},
	Eprint = {http://www.pnas.org/content/108/13/5419.full.pdf+html},
	Journal = {Proceedings of the National Academy of Sciences},
	Number = {13},
	Pages = {5419-5424},
	Title = {A synaptic organizing principle for cortical neuronal groups},
	Url = {http://www.pnas.org/content/108/13/5419.abstract},
	Volume = {108},
	Year = {2011},
	Bdsk-Url-1 = {http://www.pnas.org/content/108/13/5419.abstract},
	Bdsk-Url-2 = {http://dx.doi.org/10.1073/pnas.1016051108}}

@article{song2005,
	Abstract = {
        <p>A dataset of hundreds of recordings in which four neurons were simultaneously monitored reveals clustered connectivity patterns among cortical neurons.</p>
      },
	Author = {Song, Sen AND Sj{\"o}str{\"o}m, Per Jesper AND Reigl, Markus AND Nelson, Sacha AND Chklovskii, Dmitri B},
	Date-Added = {2012-01-26 07:38:10 +0000},
	Date-Modified = {2012-01-26 07:46:11 +0000},
	Doi = {10.1371/journal.pbio.0030068},
	Journal = {PLoS Biol},
	Month = {03},
	Number = {3},
	Pages = {e68},
	Publisher = {Public Library of Science},
	Title = {Highly Nonrandom Features of Synaptic Connectivity in Local Cortical Circuits},
	Volume = {3},
	Year = {2005},
	Bdsk-Url-1 = {http://dx.doi.org/10.1371%2Fjournal.pbio.0030068},
	Bdsk-Url-2 = {http://dx.doi.org/10.1371/journal.pbio.0030068}}

@article{Eldawlatly2009,
	Annote = {doi: 10.1162/neco.2009.11-08-900},
	Author = {Eldawlatly, Seif and Zhou, Yang and Jin, Rong and Oweiss, Karim G.},
	Booktitle = {Neural Computation},
	Da = {2010/01/01},
	Date = {2009/10/23},
	Date-Added = {2012-01-26 07:37:20 +0000},
	Date-Modified = {2012-01-26 07:37:40 +0000},
	Doi = {10.1162/neco.2009.11-08-900},
	Isbn = {0899-7667},
	Journal = {Neural Computation},
	Journal1 = {Neural Computation},
	M3 = {doi: 10.1162/neco.2009.11-08-900},
	Month = {2012/01/25},
	Number = {1},
	Pages = {158--189},
	Publisher = {MIT Press},
	Title = {On the Use of Dynamic Bayesian Networks in Reconstructing Functional Neuronal Networks from Spike Train Ensembles},
	Ty = {JOUR},
	Url = {http://dx.doi.org/10.1162/neco.2009.11-08-900},
	Volume = {22},
	Year = {2009},
	Year1 = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1162/neco.2009.11-08-900}}

@article{patnaik2011,
	Abstract = {Mining temporal network models from discrete event streams is an important problem with applications in computational neuroscience, physical plant diagnostics, and human--computer interaction modeling. In this paper, we introduce the notion of excitatory networks which are essentially temporal models where all connections are stimulative, rather than inhibitive. The emphasis on excitatory connections facilitates learning of network models by creating bridges to frequent episode mining. Specifically, we show that frequent episodes help identify nodes with high mutual information relationships and that such relationships can be summarized into a dynamic Bayesian network (DBN). This leads to an algorithm that is significantly faster than state-of-the-art methods for inferring DBNs, while simultaneously providing theoretical guarantees on network optimality. We demonstrate the advantages of our approach through an application in neuroscience, where we show how strong excitatory networks can be efficiently inferred from both mathematical models of spiking neurons and several real neuroscience datasets.},
	Affiliation = {Department of Computer Science, Virginia Tech, Blacksburg, VA 24061, USA},
	Annote = {They use a pattern-growth algorithm to discover frequent episodes which are small temporal patterns of activity. They then use a dynamic Bayesian network with these episodes as observations},
	Author = {Patnaik, Debprakash and Laxman, Srivatsan and Ramakrishnan, Naren},
	Date-Added = {2012-01-26 07:36:28 +0000},
	Date-Modified = {2012-01-26 07:36:47 +0000},
	Issn = {0219-1377},
	Issue = {2},
	Journal = {Knowledge and Information Systems},
	Keyword = {Computer Science},
	Note = {10.1007/s10115-010-0344-6},
	Pages = {273-303},
	Publisher = {Springer London},
	Title = {Discovering excitatory relationships using dynamic Bayesian networks},
	Url = {http://dx.doi.org/10.1007/s10115-010-0344-6},
	Volume = {29},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10115-010-0344-6}}

@article{bhattacharya2006,
	Abstract = {A state-space modeling approach for examining dynamic relationship between multiple brain regions was proposed in Ho, Ombao and Shumway (Ho, M.R., Ombao, H., Shumway, R., 2005. A State-Space Approach to Modelling Brain Dynamics to Appear in Statistica Sinica). Their approach assumed that the quantity representing the influence of one neuronal system over another, or effective connectivity, is time-invariant. However, more and more empirical evidence suggests that the connectivity between brain areas may be dynamic which calls for temporal modeling of effective connectivity. A Bayesian approach is proposed to solve this problem in this paper. Our approach first decomposes the observed time series into measurement error and the BOLD (blood oxygenation level-dependent) signals. To capture the complexities of the dynamic processes in the brain, region-specific activations are subsequently modeled, as a linear function of the BOLD signals history at other brain regions. The coefficients in these linear functions represent effective connectivity between the regions under consideration. They are further assumed to follow a random walk process so to characterize the dynamic nature of brain connectivity. We also consider the temporal dependence that may be present in the measurement errors. ML-II method (Berger, J.O., 1985. Statistical Decision Theory and Bayesian Analysis (2nd ed.). Springer, New York) was employed to estimate the hyperparameters in the model and Bayes factor was used to compare among competing models. Statistical inference of the effective connectivity coefficients was based on their posterior distributions and the corresponding Bayesian credible regions (Carlin, B.P., Louis, T.A., 2000. Bayes and Empirical Bayes Methods for Data Analysis (2nd ed.). Chapman and Hall, Boca Raton). The proposed method was applied to a functional magnetic resonance imaging data set and results support the theory of attentional control network and demonstrate that this network is dynamic in nature.},
	Annote = {The are using a Bayesian model to infer connectivity based on fMRI data, so this is larger scale than what we're proposing. They main thing they are working into their model is dynamic connectivity, i.e. connectivity is changing over time. They propose several models and then use Bayesian model comparison with Bayes factors to see which model works best.},
	Author = {Sourabh Bhattacharya and Moon-Ho Ringo Ho and Sumitra Purkayastha},
	Date-Added = {2012-01-26 07:35:35 +0000},
	Date-Modified = {2012-01-26 07:35:50 +0000},
	Doi = {10.1016/j.neuroimage.2005.10.019},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Model selection},
	Number = {3},
	Pages = {794 - 812},
	Title = {A Bayesian approach to modeling dynamic effective connectivity with fMRI data},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811905008001},
	Volume = {30},
	Year = {2006},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811905008001},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.neuroimage.2005.10.019}}

@article{takahashi2007,
	Annote = {They use partial directed coherence which is based on Granger causality. More to come...},
	Author = {Yasumasa Takahashi, Daniel},
	Date = {2007/12},
	Date-Added = {2012-01-26 07:32:57 +0000},
	Date-Modified = {2012-01-26 07:33:25 +0000},
	Doi = {10.1080/02664760701593065},
	Isbn = {0266-4763},
	Journal = {Journal of applied statistics},
	Number = {10},
	Pages = {1259--1273},
	Publisher = {Taylor \& Francis},
	Title = {Connectivity Inference between Neural Structures via Partial Directed Coherence},
	Ty = {JOUR},
	Volume = {34},
	Year = {2007},
	Bdsk-Url-1 = {http://dx.doi.org/10.1080/02664760701593065}}

@article{aguiar2009,
	Annote = {Somehow only the intro downloaded for this paper, but they seem to be using a really straightforward model with only one parameter... need to look into this.},
	Author = {Aguiar, Paulo and Rodrigues, Miguel},
	Date-Added = {2012-01-26 07:29:28 +0000},
	Date-Modified = {2012-01-26 07:30:02 +0000},
	Doi = {10.1186/1471-2202-10-S1-P169},
	Issn = {1471-2202},
	Journal = {BMC Neuroscience},
	Number = {Suppl 1},
	Pages = {P169},
	Title = {Neuronal connectivity inference from spike trains using an empirical probabilistic causality measure},
	Url = {http://www.biomedcentral.com/1471-2202/10/S1/P169},
	Volume = {10},
	Year = {2009},
	Bdsk-Url-1 = {http://www.biomedcentral.com/1471-2202/10/S1/P169},
	Bdsk-Url-2 = {http://dx.doi.org/10.1186/1471-2202-10-S1-P169}}

@article{gerwinn2010,
	Abstract = {Generalized Linear Models (GLMs) are commonly used statistical methods for modelling the relationship between neural population activity and presented stimuli. When the dimension of the parameter space is large, strong regularization has to be used in order to fit GLMs to datasets of realistic size without overfitting. By imposing properly chosen priors over parameters, Bayesian inference provides an effective and principled approach for achieving regularization. Here we show how the posterior distribution over model parameters of GLMs can be approximated by a Gaussian using the Expectation Propagation algorithm.  In this way, we obtain an estimate of the posterior mean and posterior covariance, allowing us to calculate Bayesian confidence intervals that characterize the uncertainty about the optimal solution.  From the posterior we also obtain a different point estimate, namely the posterior mean as opposed to the commonly used maximum a posteriori estimate. We systematically compare the different inference techniques on simulated as well as on multi-electrode recordings of retinal ganglion cells, and explore the effects of the chosen prior and the performance measure used. We find that good performance can be achieved by choosing an Laplace prior together with the posterior mean estimate.},
	Annote = {This paper is focused on using a Generalized Linear Model for single neuron activity. They use Expectation Propagation to obtain the posterior mean which contrasts with the commonly used MAP estimate.},
	Author = {Sebastian Gerwinn and Jakob H Macke and Matthias Bethge},
	Date-Added = {2012-01-26 07:27:57 +0000},
	Date-Modified = {2012-01-26 07:28:37 +0000},
	Doi = 10.3389/fncom.2010.00012,
	Issn = 1662-5188,
	Journal = {Frontiers in Computational Neuroscience},
	Number = 0,
	Title = {Bayesian inference for generalized linear models for spiking neurons},
	Url = {http://www.frontiersin.org/Journal/Abstract.aspx?s=237&name=computational_neuroscience&ART_DOI=10.3389/fncom.2010.00012},
	Volume = 4,
	Year = 2010,
	Bdsk-Url-1 = {http://www.frontiersin.org/Journal/Abstract.aspx?s=237&name=computational_neuroscience&ART_DOI=10.3389/fncom.2010.00012},
	Bdsk-Url-2 = {http://dx.doi.org/10.3389/fncom.2010.00012}}

@unpublished{mishchencko2011,
	Annote = {Model network activity in terms of a collection of coupled hidden Markov chains, with each chain corresponding to a single neuron in the network and the coupling b/w the chains reflecting the network's connectivity matrix. Use Monte Carlo Expectation-Maximization algorithm to fit parameters. To make computation feasible they used a novel (?) blockwise-Gibbs sampling method. Also implement a sparse prior on connectivity and Dale's law when estimating connectivity.},
	Author = {Yuriy Mishchencko and Joshua T. Vogelstein and Liam Paninski},
	Date-Added = {2012-01-26 07:21:30 +0000},
	Date-Modified = {2012-01-26 07:24:08 +0000},
	Note = {Submitted to the Annals of Applied Statistics},
	Title = {A Bayesian Approach For Inferring Neuronal Connectivity From Calcium Fluorescent Imaging Data},
	Year = {2011}}
